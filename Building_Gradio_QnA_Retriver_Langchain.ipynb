{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX0Lpsw2IRHHVlqFlKGY2j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/Langchain_RAG_BOT/blob/main/Building_Gradio_QnA_Retriver_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2N6Ntit2zRAA"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_core langgraph langchain langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain_community pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo9ITyDxzac1",
        "outputId": "b3fbc3e4-4d70-4cc1-e144-d3e01cf81f44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/292.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m286.7/292.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/HAI_AI-Index-Report-2024.pdf\")"
      ],
      "metadata": {
        "id": "kmj_sndO0gEf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=loader.load()"
      ],
      "metadata": {
        "id": "yhXjLTX50nOT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-text-splitters"
      ],
      "metadata": {
        "id": "F5z-BmQQ0ozG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "0vZ1LQRR32It"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs=text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "Ez2WZJ7434Po"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPY9IyAh4Aau",
        "outputId": "612f5dd8-cc30-4c10-8e11-dceec0f69982"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/245.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "inference_api_key = getpass.getpass(\"Enter your HF Inference API Key:\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUPqHKPT4Nex",
        "outputId": "a55dd40b-310c-4e83-ce9f-71e3e3011b80"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your HF Inference API Key:\n",
            "\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "    api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdT2ebcW4PlU",
        "outputId": "6904cd1e-27a5-4edc-9ffb-997351cb7ed1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-community faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykHw-dE04rik",
        "outputId": "568ef3c0-3a35-4e7d-e602-5550589e1eca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/27.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/27.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/27.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/27.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/27.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/27.0 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m18.9/27.0 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m22.4/27.0 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m24.4/27.0 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "de44T38r48fn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db=FAISS.from_documents(docs,embeddings)"
      ],
      "metadata": {
        "id": "hTRgPZk45C0H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "nXXV0fUY5P-W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDAwT4Qa8bjZ",
        "outputId": "930bef34-502f-41a2-bf4d-8a984dba18a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(model=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dk0gTeh8L9R",
        "outputId": "05b88248-d443-4465-946c-911b7ec082a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "results = rag_chain.invoke({\"input\": \"What is this report about\"})\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fB9HhTBMLS",
        "outputId": "924b6f64-6f6b-4e70-eb98-c77b9cb8770f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is this report about',\n",
              " 'context': [Document(metadata={'source': '/content/HAI_AI-Index-Report-2024.pdf', 'page': 434}, page_content='CHAPTER 9:\\nPublic \\nOpinionArtificial Intelligence\\nIndex Report 2024'),\n",
              "  Document(metadata={'source': '/content/HAI_AI-Index-Report-2024.pdf', 'page': 426}, page_content='427\\nArtificial Intelligence\\nIndex Report 2024 Chapter 8 Preview Table of Contents20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\nMale\\nFemaleNew inf ormatics, CS, CE, and IT mast er’s grad uates (% of t otal)Austria Belgium Bulgaria Czech R epublic\\nEstonia Finland Franc e Germany\\nIreland Italy Latvia Lithuania\\nNetherlands Norway Poland Portugal\\nRomania Spain Switzerland Turkey\\nUnited Kingdom73.32%\\n26.68%86.33%\\n13.67%59.57%\\n40.43%78.98%\\n21.02%\\n58.02%\\n41.98%72.43%\\n27.57%76.86%\\n23.14%76.49%\\n23.51%\\n68.83%\\n31.17%85.91%\\n14.09%74.60%\\n25.40%81.51%\\n18.49%\\n76.50%\\n23.50%71.43%\\n28.57%81.41%\\n18.59%81.24%\\n18.76%\\n58.09%\\n41.91%78.06%\\n21.94%84.19%\\n15.81%65.30%\\n34.70%\\n68.67%\\n31.33%Gender of ne w inf ormatics, CS , CE, and IT mast er’s graduates (% of t otal) in E urope, 2011–22\\nSource: Inf ormatics E urope, 2023 | C hart: 202 4 AI Inde x repor t8.1 AI Postsecondary EducationChapter 8: Diversity\\nFigure 8.1.16Artificial Intelligence\\nIndex Report 2024'),\n",
              "  Document(metadata={'source': '/content/HAI_AI-Index-Report-2024.pdf', 'page': 425}, page_content='426\\nArtificial Intelligence\\nIndex Report 2024 Chapter 8 Preview Table of Contents20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\n20132016201920220%50%100%\\nMale\\nFemaleNew inf ormatics, CS, CE, and IT bachelor ’s grad uates (% of t otal)Austria Belgium Bulgaria Czech R epublic\\nEstonia Finland Franc e Germany\\nIreland Italy Latvia Lithuania\\nNetherlands Norway Poland Portugal\\nRomania Spain Switzerland Turkey\\nUnited Kingdom80.26%\\n19.74%92.07%\\n7.93%64.77%\\n35.23%83.78%\\n16.22%\\n76.00%\\n24.00%75.35%\\n24.65%85.25%\\n14.75%78.51%\\n21.49%\\n83.71%\\n16.29%85.95%\\n14.05%78.97%\\n21.03%87.02%\\n12.98%\\n78.42%\\n21.58%78.63%\\n21.37%85.53%\\n14.47%85.04%\\n14.96%\\n66.60%\\n33.40%85.68%\\n14.32%86.81%\\n13.19%70.73%\\n29.27%\\n82.2 1%\\n17.79%Gender of ne w inf ormatics, CS , CE, and IT ba chelor ’s graduates (% of t otal) in E urope, 2011–22\\nSource: Inf ormatics E urope, 2023 | C hart: 202 4 AI Inde x repor t8.1 AI Postsecondary EducationChapter 8: Diversity\\nFigure 8.1.15Artificial Intelligence\\nIndex Report 2024'),\n",
              "  Document(metadata={'source': '/content/HAI_AI-Index-Report-2024.pdf', 'page': 0}, page_content='Artificial  \\nIntelligence\\nIndex Report \\n2024')],\n",
              " 'answer': 'This report, the \"Artificial Intelligence Index Report 2024\", appears to be about public opinion on artificial intelligence and its education in Europe.'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results[\"context\"][0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS08_IJABS3H",
        "outputId": "136e3b16-eb0f-4340-f236-df2a31edebb9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER 9:\n",
            "Public \n",
            "OpinionArtificial Intelligence\n",
            "Index Report 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(results[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpXdZkzmBbZ8",
        "outputId": "7635f1b5-9bcd-4db3-871c-7905a90b95b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This report, the \"Artificial Intelligence Index Report 2024\", appears to be about public opinion on artificial intelligence and its education in Europe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: similar code for ours:from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "# from langchain_core.chat_history import BaseChatMessageHistory\n",
        "# from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "# store = {}\n",
        "# def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "#     if session_id not in store:\n",
        "#         store[session_id] = ChatMessageHistory()\n",
        "#     re\n",
        "\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "class ChatWithHistory(RunnableWithMessageHistory):\n",
        "    retriever: object\n",
        "    llm: object\n",
        "    prompt: object\n",
        "    def __init__(self, retriever, llm, prompt):\n",
        "        super().__init__(get_session_history)\n",
        "        self.retriever = retriever\n",
        "        self.llm = llm\n",
        "        self.prompt = prompt\n",
        "    def invoke(self, input_str, config=None):\n",
        "        question_answer_chain = create_stuff_documents_chain(self.llm, self.prompt)\n",
        "        rag_chain = create_retrieval_chain(self.retriever, question_answer_chain)\n",
        "        result = rag_chain.invoke({\"input\": input_str})\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "VnXcbxi1Tlmr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\n",
        "    {\"input\": \"What is This report about?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"abc123\"}\n",
        "    },  # constructs a key \"abc123\" in `store`.\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "U5aU07pjTsUB",
        "outputId": "89f9a82f-f5bd-4167-d16d-7be7552dda35"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This report appears to be about artificial intelligence (AI) and its relationship to public opinion, education, and demographics. Specifically, it discusses the diversity of master's graduates in informatics, computer science, computer engineering, and IT fields in Europe.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\n",
        "    {\"input\": \"Did you say artificial intelligence?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"abc123\"}\n",
        "    },  # constructs a key \"abc123\" in `store`.\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "auy51L7xT3ew",
        "outputId": "619259b9-cec6-49a7-cad0-d6c3e243cfa1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, I did.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def qa_function(query):\n",
        "  results = rag_chain.invoke({\"input\": query})\n",
        "  return results[\"answer\"]\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=qa_function,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"HAI AI Index Report 2024 Q&A\",\n",
        "    description=\"Ask questions about the HAI AI Index Report 2024.\",\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "1b2gsFUxBrXw",
        "outputId": "3ef05132-99d7-4a07-cc91-6fe12f32e16a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c5736939dbba964063.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c5736939dbba964063.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def qa_function(query):\n",
        "    results = rag_chain.invoke({\"input\": query})\n",
        "    return results[\"answer\"]\n",
        "\n",
        "# CSS for custom styling\n",
        "custom_css = \"\"\"\n",
        "#title-header {\n",
        "    font-size: 32px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\n",
        "    color: #2E8B57;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "\n",
        "#description-text {\n",
        "    font-size: 18px;\n",
        "    text-align: center;\n",
        "    margin-bottom: 20px;\n",
        "    color: #555;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    background: linear-gradient(135deg, #f3f4f6, #ffffff);\n",
        "    padding: 50px;\n",
        "    border-radius: 15px;\n",
        "    box-shadow: 0px 4px 20px rgba(0, 0, 0, 0.1);\n",
        "}\n",
        "\n",
        ".gr-button {\n",
        "    background-color: #2E8B57;\n",
        "    color: white;\n",
        "    font-weight: bold;\n",
        "    padding: 12px;\n",
        "    border-radius: 10px;\n",
        "}\n",
        "\n",
        ".gr-textbox {\n",
        "    border: 2px solid #2E8B57;\n",
        "    border-radius: 8px;\n",
        "    font-size: 16px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=qa_function,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=2,\n",
        "        placeholder=\"Enter your question here...\",\n",
        "        label=\"Your Question:\",\n",
        "        elem_classes=[\"gr-textbox\"]\n",
        "    ),\n",
        "    outputs=gr.Textbox(label=\"Answer\", elem_classes=[\"gr-textbox\"]),\n",
        "    title=\"HAI AI Index Report 2024 Q&A\",\n",
        "    description=\"Ask questions about the HAI AI Index Report 2024.\",\n",
        "    css=custom_css\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "Qbg9I6upCjxH",
        "outputId": "68abc0f6-5d47-4dd5-ebf7-245168cfa362"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://59f2a8e348dc12f372.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://59f2a8e348dc12f372.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0x5GZJzDzUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}