{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQMjXkr056/97JLN72RdsC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/Langchain_RAG_BOT/blob/main/Learning_Enhanced_RAG_(LE_RAG).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRQnytfFMfj5",
        "outputId": "cc798061-5dd2-422e-a309-e591f930e734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRw2VwCuP_Sx",
        "outputId": "b58603ac-0cc7-4167-f166-4e3fc703640e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.3.18)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (3.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.23.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain_core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain_core) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oypkKG6YQ01f",
        "outputId": "24c27fe6-b14c-4cb5-f475-d93efc8ff270"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ6V1MUTY-2F",
        "outputId": "62fa3a50-ec1f-4b9d-f210-2f7754c84492"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.vectorstores import VectorStoreRetriever\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "Bxh1-pqNPOSp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw3i2PF6PhUO",
        "outputId": "c6423ddb-8fbe-4b72-860e-4740e206ee22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGroq(model='llama-3.1-8b-instant',temperature=0.5)"
      ],
      "metadata": {
        "id": "ARIdWnvDRP9w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_query(query):\n",
        "    \"\"\"Classify user query into types for enhanced processing.\"\"\"\n",
        "    if \"how\" in query or \"impact\" in query:\n",
        "        return \"analytical\"\n",
        "    elif \"what\" in query or \"definition\" in query:     #Function to classify the query\n",
        "        return \"factual\"\n",
        "    elif \"example\" in query or \"case\" in query:\n",
        "        return \"opinion\"\n",
        "    else:\n",
        "        return \"contextual\""
      ],
      "metadata": {
        "id": "utTkB81ER-3H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "Nb_vkmDthUGf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "foj6fwy9hd00"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_query(query):\n",
        "    \"\"\"Enhance the original query using a language model.\"\"\"\n",
        "    system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized\n",
        "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
        "    re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
        "    enhanced_query = question_rewriter.invoke({\"question\": query})\n",
        "    return enhanced_query"
      ],
      "metadata": {
        "id": "Rfw_AQ_UhBuB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_documents_from_urls(urls):# dont run\n",
        "    \"\"\"Fetch content from provided URLs and return as documents.\"\"\"\n",
        "    documents = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise an error for bad responses\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            text = soup.get_text(separator=' ', strip=True)  # Extract text\n",
        "            documents.append({\"text\": text, \"metadata\": {\"source\": url}})\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to fetch {url}: {e}\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "f__Xgsc-Sbtc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIfrlW_7V8-M",
        "outputId": "73e5d391-39a0-4943-e393-988cf288e6a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_list = [\n",
        "    \"https://www.cisa.gov/uscert/ncas/current-activity\",\n",
        "    \"https://www.kaspersky.com/resource-center/threats\",\n",
        "    \"https://www.cyber.gov.au/acsc/view-all-content/publications\"\n",
        "]"
      ],
      "metadata": {
        "id": "1Wo_O6XISfY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "urls = [\n",
        "    \"https://www.simplilearn.com/tutorials/cyber-security-tutorial/types-of-cyber-attacks\",\n",
        "    \"https://www.fortinet.com/resources/cyberglossary/types-of-cyber-attacks\",\n",
        "    \"https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html\",\n",
        "]"
      ],
      "metadata": {
        "id": "tZqHf9TcXqWC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader=WebBaseLoader(urls)"
      ],
      "metadata": {
        "id": "h5tiyUtJWJIQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "zgkU8nnUSjQY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "documents = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "ovzOxBCJYDme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8e2a74-426c-4bca-b034-c454271e3d6d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10335, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2573, which is longer than the specified 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhUhEgqXh-LF",
        "outputId": "e64c15dc-8be7-4962-8994-40015d6556f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://www.simplilearn.com/tutorials/cyber-security-tutorial/types-of-cyber-attacks', 'title': 'Types of Cyber Attacks You Should Be Aware of in 2025', 'description': 'There are many varieties of cyber attacks that happen in the world. If we know the various types of cyberattacks, it becomes easier for us to protect our networks. Know more!', 'language': 'en-US'}, page_content='Types of Cyber Attacks You Should Be Aware of in 2025')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "inference_api_key = getpass.getpass(\"Enter your HF Inference API Key:\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB7FsynlYtxo",
        "outputId": "ee8160c4-3bab-47bb-b60d-decfbaff9430"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your HF Inference API Key:\n",
            "\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "    api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
        ")"
      ],
      "metadata": {
        "id": "q0VAa9swYw1I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if documents:\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = VectorStoreRetriever(vectorstore=vectorstore)\n",
        "else:\n",
        "    raise ValueError(\"No documents were fetched. Please check the URLs.\")\n"
      ],
      "metadata": {
        "id": "dohgyiAWSlm_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        ")"
      ],
      "metadata": {
        "id": "HVWUs18mYXmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c755f67a-cf3d-400f-d5ea-3b792afaaa25"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-41a58f208115>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the types of cyber attacks?\"\n",
        "enhanced_query = enhance_query(query)\n",
        "result = qa_chain({\"query\": enhanced_query})\n",
        "print(result[\"result\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozPLo6H4gVvh",
        "outputId": "3d468c27-fdc0-4fa3-e00c-bf5504abe464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-d30b7348edce>:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": enhanced_query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your re-formulated question is indeed more specific and granular, making it more suitable for vectorstore retrieval. By including specific keywords, categories, subtypes, and characteristics, you're providing a richer context for the vectorstore to understand the semantic intent and meaning behind the question.\n",
            "\n",
            "Here are some suggestions to further optimize the question for vectorstore retrieval:\n",
            "\n",
            "1. **Use more precise keywords**: Instead of using general terms like \"cyber attacks,\" consider using more specific phrases like \"types of cyber threats,\" \"cybersecurity attack vectors,\" or \"malware attack classifications.\"\n",
            "2. **Add relevant context**: Provide some background information or context that might help the vectorstore understand the scope and relevance of the question. For example, you could mention the industry, organization, or specific systems that the question is related to.\n",
            "3. **Use a more formal query structure**: Consider using a more structured query format, such as a question with a specific question mark, followed by a brief description of the context and requirements. This can help the vectorstore better understand the intent and requirements of the question.\n",
            "4. **Use synonyms and related terms**: Consider including synonyms or related terms for the keywords you're using. For example, instead of just using \"malware,\" you could also include \"viruses,\" \"trojans,\" or \"spyware.\"\n",
            "5. **Specify the desired output format**: If you have a specific format in mind for the answer, such as a list, table, or graph, be sure to include it in the question. This can help the vectorstore understand how to present the information in a way that's most useful to you.\n",
            "\n",
            "Here's an updated version of the re-formulated question that incorporates these suggestions:\n",
            "\n",
            "\"Identify and list the categories of cyber threats, including malware, phishing, ransomware, and other types of attacks, as well as their subtypes and characteristics. Provide a detailed description of each category, including their typical attack vectors, common targets, and potential consequences. The answer should be presented in a table format, with columns for category name, subtype, characteristics, and examples. Please include only relevant and up-to-date information, and exclude any sensitive or proprietary details.\"\n",
            "\n",
            "By making these adjustments, you can further optimize the question for vectorstore retrieval and increase the likelihood of getting accurate and relevant results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dont Run below code as CPU useage:Try compressioning the code"
      ],
      "metadata": {
        "id": "yh4Ryj0HrllK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gather_feedback(response, user_feedback, retriever, query_type, memory):\n",
        "    \"\"\"\n",
        "    Collect user feedback and simulate continuous learning.\n",
        "    Adjust the query classification or retriever based on feedback.\n",
        "    \"\"\"\n",
        "    print(\"User Feedback: \", user_feedback)\n",
        "\n",
        "    # If feedback is irrelevant, simulate adjusting query enhancement or document relevance\n",
        "    if user_feedback.lower() == \"irrelevant\":\n",
        "        print(\"Adjusting the query classification or retrieval process...\")\n",
        "\n",
        "        # 1. Change the query classification if it misclassified\n",
        "        if query_type == \"factual\":\n",
        "            print(\"Reclassifying query as 'analytical'.\")\n",
        "            query_type = \"analytical\"  # Adjust classification for future runs\n",
        "\n",
        "        # 2. Alternatively, adjust the document retriever for future queries\n",
        "        print(\"Increasing importance of document feedback...\")\n",
        "        memory.save_context({\"feedback\": \"irrelevant\"}, {\"response\": response})\n",
        "\n",
        "    else:\n",
        "        print(\"Feedback noted. The system will continue with the current process.\")\n"
      ],
      "metadata": {
        "id": "MCZ25_G3rZ7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Main Function to Handle User Queries\n",
        "def handle_user_query(query):\n",
        "    \"\"\"Process user query, enhance it, retrieve relevant documents, and generate a response.\"\"\"\n",
        "    # Classify the query\n",
        "    query_type = classify_query(query)\n",
        "    print(f\"Query Type: {query_type}\")\n",
        "\n",
        "    # Enhance the query\n",
        "    enhanced_query = enhance_query(query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    # Retrieve relevant documents\n",
        "    retrieved_docs = retriever.get_relevant_documents(enhanced_query)\n",
        "    if retrieved_docs:\n",
        "        print(f\"Retrieved Documents: {retrieved_docs}\")\n",
        "    else:\n",
        "        print(\"No documents found for the enhanced query.\")\n",
        "        return\n",
        "\n",
        "    # Generate response\n",
        "    response = qa_chain.run(input=enhanced_query)  # Pass enhanced_query as the input\n",
        "    print(f\"Generated Response: {response}\")\n",
        "\n",
        "    # Simulating user feedback for learning\n",
        "    user_feedback = input(\"Please provide feedback on the response (relevant/irrelevant): \")\n",
        "    gather_feedback(response, user_feedback, retriever, query_type, memory)\n",
        "\n",
        "# Step 11: Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = input(\"Enter your cybersecurity query: \")\n",
        "    handle_user_query(user_query)"
      ],
      "metadata": {
        "id": "2lzlPX2Prg17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compressed code(Better CPU load)"
      ],
      "metadata": {
        "id": "krTT-_WnrvIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_feedback_loop_simulation(num_iterations=5):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        print(f\"\\n--- Iteration {i+1} ---\")\n",
        "\n",
        "        # 1. User Query Input (Simulate)\n",
        "        user_query = input(\"Enter your query: \")\n",
        "\n",
        "        # 2. Query Classification\n",
        "        query_type = classify_query(user_query)\n",
        "        print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "        # 3. Query Enhancement (Optional, based on query type)\n",
        "        if query_type == \"analytical\" or query_type == \"factual\":\n",
        "            enhanced_query = enhance_query(user_query)\n",
        "            print(f\"Enhanced Query: {enhanced_query}\")\n",
        "        else:\n",
        "            enhanced_query = user_query\n",
        "\n",
        "        # 4. Retrieval & Answer Generation\n",
        "        result = qa_chain({\"query\": enhanced_query})\n",
        "        print(f\"Answer:\\n{result['result']}\")\n",
        "\n",
        "        # 5. Feedback Collection (Simulate)\n",
        "        feedback = input(\"Was the answer helpful? (yes/no): \")\n",
        "\n",
        "        # 6. Feedback Processing and System Update (Placeholder)\n",
        "        if feedback.lower() == \"no\":\n",
        "            print(\"System needs improvement based on feedback.\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_feedback_loop_simulation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ZJgP62glgVk",
        "outputId": "569b9f5c-fdaa-4304-df55-a26107ab2a99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iteration 1 ---\n",
            "Enter your query: what is sql\n",
            "Query type classified as: factual\n",
            "Enhanced Query: Here's a rewritten version of the question optimized for vectorstore retrieval:\n",
            "\n",
            "\"What is the definition and purpose of SQL, including its syntax, functionality, and applications in database management?\"\n",
            "\n",
            "This rewritten question is more specific and includes additional context that can help vectorstore retrieval algorithms better understand the underlying semantic intent. The added keywords such as \"definition\", \"syntax\", \"functionality\", and \"applications\" can help improve the accuracy of the retrieval results.\n",
            "\n",
            "Alternatively, you could also break down the question into sub-questions to further refine the search:\n",
            "\n",
            "* \"What is the definition of SQL?\"\n",
            "* \"What is the syntax of SQL?\"\n",
            "* \"What are the main functionalities of SQL?\"\n",
            "* \"What are some common applications of SQL in database management?\"\n",
            "\n",
            "This approach can help to retrieve more relevant results and provide a better understanding of the underlying semantic intent.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-fbfaa254b7c6>:22: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": enhanced_query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "SQL (Structured Query Language) is a programming language designed for managing and manipulating data stored in relational database management systems (RDBMS). The primary purpose of SQL is to provide a standard way of interacting with databases, allowing users to perform various operations such as creating, modifying, and querying database schema and data.\n",
            "\n",
            "**Definition and Purpose:**\n",
            "\n",
            "SQL is a declarative language, meaning that users specify what they want to do with their data, rather than how to do it. This allows SQL to optimize the query execution plan and improve performance. SQL is used for various purposes, including:\n",
            "\n",
            "* Creating and modifying database schema\n",
            "* Inserting, updating, and deleting data\n",
            "* Querying data using SELECT statements\n",
            "* Managing database security and permissions\n",
            "\n",
            "**Syntax:**\n",
            "\n",
            "SQL syntax consists of several components, including:\n",
            "\n",
            "* Keywords: Such as SELECT, FROM, WHERE, GROUP BY, HAVING, etc.\n",
            "* Identifiers: Table names, column names, and other database objects\n",
            "* Literals: Values enclosed in quotes, such as strings and numbers\n",
            "* Operators: Used for comparison, arithmetic, and logical operations\n",
            "* Functions: Built-in functions, such as SUM, COUNT, and AVG\n",
            "\n",
            "**Functionality:**\n",
            "\n",
            "SQL provides various functionalities, including:\n",
            "\n",
            "* Data definition language (DDL): Used to create, modify, and drop database schema\n",
            "* Data manipulation language (DML): Used to insert, update, and delete data\n",
            "* Data query language (DQL): Used to retrieve data from the database\n",
            "* Data control language (DCL): Used to manage database security and permissions\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "SQL is widely used in various applications, including:\n",
            "\n",
            "* Database administration: SQL is used to manage and maintain databases, including creating and modifying schema, and optimizing database performance.\n",
            "* Data analysis: SQL is used to retrieve and manipulate data for analysis and reporting.\n",
            "* Business intelligence: SQL is used to create reports and dashboards for business decision-making.\n",
            "* Web development: SQL is used to interact with databases in web applications, such as e-commerce platforms and social media sites.\n",
            "\n",
            "Some common SQL commands include:\n",
            "\n",
            "* CREATE TABLE: Creates a new table in the database\n",
            "* INSERT INTO: Inserts new data into a table\n",
            "* SELECT: Retrieves data from a table\n",
            "* UPDATE: Modifies existing data in a table\n",
            "* DELETE: Deletes data from a table\n",
            "* DROP TABLE: Deletes a table from the database\n",
            "\n",
            "Overall, SQL is a powerful language for managing and manipulating data in relational databases, and its syntax, functionality, and applications make it an essential tool for database administrators, data analysts, and developers.\n",
            "Was the answer helpful? (yes/no): yes\n",
            "\n",
            "--- Iteration 2 ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fbfaa254b7c6>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mrun_feedback_loop_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-fbfaa254b7c6>\u001b[0m in \u001b[0;36mrun_feedback_loop_simulation\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# 1. User Query Input (Simulate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# 2. Query Classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_feedback_loop_simulation(num_iterations=5):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        print(f\"\\n--- Iteration {i+1} ---\")\n",
        "\n",
        "        # 1. User Query Input (Simulate)\n",
        "        user_query = input(\"Enter your query: \")\n",
        "\n",
        "        # 2. Query Classification\n",
        "        query_type = classify_query(user_query)\n",
        "        print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "        # 3. Query Enhancement (Optional, based on query type)\n",
        "        if query_type == \"analytical\" or query_type == \"factual\":\n",
        "            enhanced_query = enhance_query(user_query)\n",
        "            print(f\"Enhanced Query: {enhanced_query}\")\n",
        "        else:\n",
        "            enhanced_query = user_query\n",
        "\n",
        "        # 4. Retrieval & Answer Generation\n",
        "        result = qa_chain({\"query\": enhanced_query})\n",
        "        print(f\"Answer:\\n{result['result']}\")\n",
        "\n",
        "        # 5. Feedback Collection (Simulate)\n",
        "        feedback = input(\"Was the answer helpful? (yes/no): \")\n",
        "\n",
        "        # 6. Feedback Processing and System Update (Placeholder)\n",
        "        if feedback.lower() == \"no\":\n",
        "            why_not_helpful = input(\"Why was the answer not helpful? \") # Added input for reason\n",
        "            print(f\"User provided reason: {why_not_helpful}\") # Print the reason\n",
        "            print(\"System needs improvement based on feedback.\")\n",
        "        else:\n",
        "            print(\"Feedback noted. The system will continue with the current process.\") # Optional positive feedback print\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_feedback_loop_simulation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pigyVxOHhFrc",
        "outputId": "683e03d4-5279-4b7c-9d4a-d83559e681da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iteration 1 ---\n",
            "Enter your query: what is sql\n",
            "Query type classified as: factual\n",
            "Enhanced Query: Here's a re-formulated version of the question optimized for vector store retrieval:\n",
            "\n",
            "\"What is SQL definition, purpose, and usage in database management systems?\"\n",
            "\n",
            "This improved question:\n",
            "\n",
            "1. **Adds specificity**: By asking for the \"definition, purpose, and usage\" of SQL, we're providing more context and making it easier for the vector store to retrieve relevant information.\n",
            "2. **Uses more precise keywords**: Instead of just asking \"what is SQL\", we're using more specific keywords like \"definition\", \"purpose\", and \"usage\" to capture the underlying semantic intent.\n",
            "3. **Expands the scope**: By mentioning \"database management systems\", we're making it clear that we're interested in SQL in the context of databases, which can help the vector store retrieve more relevant information.\n",
            "\n",
            "This reformulated question should be more effective at retrieving relevant information from a vector store, as it provides more context and specificity about the underlying semantic intent.\n",
            "Answer:\n",
            "SQL (Structured Query Language) is a standard programming language designed for managing and manipulating data in relational database management systems (RDBMS). \n",
            "\n",
            "**Definition:** SQL is a declarative language used to perform various operations on data stored in a database, such as creating and modifying database structures, inserting, updating, and deleting data, as well as querying data.\n",
            "\n",
            "**Purpose:** The primary purpose of SQL is to provide a common language for interacting with relational databases, allowing users to manage and analyze data in a structured and efficient manner. SQL enables developers to write database queries, create database structures, and perform various operations on data, making it a fundamental tool for database management.\n",
            "\n",
            "**Usage:** SQL is widely used in various applications, including:\n",
            "\n",
            "1. Database management: SQL is used to create, modify, and manage database structures, such as tables, indexes, and views.\n",
            "2. Data analysis: SQL is used to query and analyze data in databases, allowing users to extract insights and information from large datasets.\n",
            "3. Data manipulation: SQL is used to insert, update, and delete data in databases, ensuring data consistency and integrity.\n",
            "4. Reporting and business intelligence: SQL is used to generate reports and perform business intelligence tasks, such as data mining and data warehousing.\n",
            "\n",
            "Some common SQL operations include:\n",
            "\n",
            "* SELECT: Retrieves data from a database table.\n",
            "* INSERT: Adds new data to a database table.\n",
            "* UPDATE: Modifies existing data in a database table.\n",
            "* DELETE: Deletes data from a database table.\n",
            "* CREATE: Creates a new database structure, such as a table or index.\n",
            "* DROP: Deletes an existing database structure.\n",
            "\n",
            "Overall, SQL is a powerful and versatile language that plays a crucial role in managing and analyzing data in relational databases.\n",
            "Was the answer helpful? (yes/no): no\n",
            "Why was the answer not helpful? need more details \n",
            "User provided reason: need more details \n",
            "System needs improvement based on feedback.\n",
            "\n",
            "--- Iteration 2 ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f3d4182d884f>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mrun_feedback_loop_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-f3d4182d884f>\u001b[0m in \u001b[0;36mrun_feedback_loop_simulation\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# 1. User Query Input (Simulate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# 2. Query Classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnOEQIG4jsce",
        "outputId": "6c48b461-99b9-45e5-ba3f-5876a9886744"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio)\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.4 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.vectorstores import VectorStoreRetriever\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import getpass\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "\n",
        "# ... (Your existing code for setup, functions, etc.)\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "\n",
        "    # 1. Query Classification\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    # 2. Query Enhancement\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    # 3. Retrieval & Answer Generation\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def feedback_function(user_query, feedback):\n",
        "    if feedback.lower() == \"yes\":\n",
        "        return \"Thank you for your feedback. The process continues.\"\n",
        "    else:\n",
        "        reason = gr.Textbox(label=\"Reason for irrelevant answer:\")\n",
        "        return f\"Why was the answer not helpful? {reason}\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "      user_query = gr.Textbox(label=\"Enter your query\")\n",
        "      submit = gr.Button(\"Submit\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "    with gr.Row():\n",
        "      feedback_button_yes = gr.Button(\"Yes\")\n",
        "      feedback_button_no = gr.Button(\"No\")\n",
        "\n",
        "    feedback_textbox = gr.Textbox(label = \"Feedback\")\n",
        "\n",
        "    def submit_event(user_query):\n",
        "      return run_feedback_loop_simulation(user_query), \"\"\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer,feedback_textbox])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val):\n",
        "        if feedback_val == \"Yes\":\n",
        "            return \"Thank you for your feedback. The process continues.\", gr.update(value=\"\")\n",
        "        else:\n",
        "            return \"Please provide a reason.\", gr.update(visible=True)\n",
        "\n",
        "    feedback_button_yes.click(fn=handle_feedback, inputs=[answer,feedback_button_yes], outputs=[feedback_textbox, feedback_textbox])\n",
        "    feedback_button_no.click(fn=handle_feedback, inputs=[answer,feedback_button_no], outputs=[feedback_textbox, feedback_textbox])\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "NOznZBejjjvK",
        "outputId": "a40158b5-f83d-4322-8c4a-b1eeafea886b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2dfbf168f0369b62c5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2dfbf168f0369b62c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intial code\n",
        "import gradio as gr\n",
        "\n",
        "# ... (Your existing code for setup, functions, etc.)\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "\n",
        "    # 1. Query Classification\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    # 2. Query Enhancement\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    # 3. Retrieval & Answer Generation\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def feedback_function(user_query, feedback, reason=\"\"):\n",
        "    if feedback.lower() == \"yes\":\n",
        "        return \"Thank you for your feedback. The process continues.\", gr.update(visible=False), \"\"\n",
        "    else:\n",
        "        return \"Why was the answer not helpful?\", gr.update(visible=True), \"\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label=\"Enter your query\")\n",
        "        submit = gr.Button(\"Submit\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "    with gr.Row():\n",
        "        feedback_button_yes = gr.Button(\"Yes\")\n",
        "        feedback_button_no = gr.Button(\"No\")\n",
        "\n",
        "    feedback_textbox = gr.Textbox(label=\"Feedback\", visible=False)\n",
        "    reason_textbox = gr.Textbox(label=\"Reason\", visible=False)\n",
        "\n",
        "\n",
        "    def submit_event(user_query):\n",
        "        return run_feedback_loop_simulation(user_query), \"\", gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer, feedback_textbox, reason_textbox, feedback_textbox])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val, reason=\"\"):\n",
        "        if feedback_val == \"Yes\":\n",
        "            return \"Thank you for your feedback. The process continues.\", gr.update(visible=False), gr.update(visible=False), \"\"\n",
        "        else:\n",
        "            return \"Please provide a reason:\", gr.update(visible=True), gr.update(visible=True), \"\"\n",
        "\n",
        "    feedback_button_yes.click(fn=handle_feedback, inputs=[answer, feedback_button_yes], outputs=[feedback_textbox, reason_textbox, feedback_textbox, answer])\n",
        "    feedback_button_no.click(fn=handle_feedback, inputs=[answer, feedback_button_no], outputs=[feedback_textbox, reason_textbox, feedback_textbox, answer])\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "sxi6GBi3lgnf",
        "outputId": "7ca932de-9bd4-4cb6-d346-061590890fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://42e342101dcfb2bab1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://42e342101dcfb2bab1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iteration 1(Buttons not working)\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label=\"Enter your query\")\n",
        "        submit = gr.Button(\"Submit\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "    feedback_textbox = gr.Textbox(label=\"Feedback\", visible=False)\n",
        "    reason_textbox = gr.Textbox(label=\"Reason\", visible=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        feedback_button_yes = gr.Button(\"Yes\")\n",
        "        feedback_button_no = gr.Button(\"No\")\n",
        "\n",
        "    def submit_event(user_query):\n",
        "        return run_feedback_loop_simulation(user_query), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer, feedback_textbox, reason_textbox])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val, reason=\"\"):\n",
        "        if feedback_val == \"Yes\":\n",
        "            return \"Thank you for your feedback. The process continues.\", gr.update(visible=False), gr.update(visible=False)\n",
        "        else:\n",
        "            return \"Please provide a reason:\", gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    feedback_button_yes.click(fn=handle_feedback, inputs=[answer, feedback_button_yes, reason_textbox], outputs=[feedback_textbox, reason_textbox, feedback_textbox])\n",
        "    feedback_button_no.click(fn=handle_feedback, inputs=[answer, feedback_button_no, reason_textbox], outputs=[feedback_textbox, reason_textbox, feedback_textbox])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "h7Gy1ePIoPa4",
        "outputId": "8dc33cc8-8ce8-40f2-a3f8-78954e304e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://215f1c812ab1817919.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://215f1c812ab1817919.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iteration 2(reason space not working)\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label=\"Enter your query\")\n",
        "        submit = gr.Button(\"Submit\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "    feedback_textbox = gr.Textbox(label=\"Feedback\", visible=False)\n",
        "    reason_textbox = gr.Textbox(label=\"Reason\", visible=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        feedback_button_yes = gr.Button(\"Yes\")\n",
        "        feedback_button_no = gr.Button(\"No\")\n",
        "\n",
        "    def submit_event(user_query):\n",
        "        # Reset the visibility of feedback fields when a new query is submitted\n",
        "        return run_feedback_loop_simulation(user_query), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer, feedback_textbox, reason_textbox])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val):\n",
        "        # Display a thank you message if feedback is \"Yes\" or prompt for a reason if \"No\"\n",
        "        if feedback_val == \"Yes\":\n",
        "            return \"Thank you for your feedback. The process continues.\", gr.update(visible=False), gr.update(visible=False)\n",
        "        else:\n",
        "            return \"Please provide a reason:\", gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    # Use lambda functions to pass \"Yes\" or \"No\" as feedback values\n",
        "    feedback_button_yes.click(fn=lambda answer: handle_feedback(answer, \"Yes\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, feedback_textbox])\n",
        "    feedback_button_no.click(fn=lambda answer: handle_feedback(answer, \"No\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, feedback_textbox])\n",
        "\n",
        "demo.launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "ex1qG0PGmxXb",
        "outputId": "40f9de8b-23b3-4ebd-fba0-5353b4cc9b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1ca9abf8f150f478b2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1ca9abf8f150f478b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iteration 3(No submit button)\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label=\"Enter your query\")\n",
        "        submit = gr.Button(\"Submit\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "    feedback_textbox = gr.Textbox(label=\"Feedback\", visible=False)\n",
        "    reason_textbox = gr.Textbox(label=\"Reason\", visible=False, interactive=True)  # Set interactive=True for typing\n",
        "\n",
        "    with gr.Row():\n",
        "        feedback_button_yes = gr.Button(\"Yes\")\n",
        "        feedback_button_no = gr.Button(\"No\")\n",
        "\n",
        "    def submit_event(user_query):\n",
        "        # Reset the visibility of feedback fields when a new query is submitted\n",
        "        return run_feedback_loop_simulation(user_query), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer, feedback_textbox, reason_textbox])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val):\n",
        "        # Display a thank you message if feedback is \"Yes\" or prompt for a reason if \"No\"\n",
        "        if feedback_val == \"Yes\":\n",
        "            return \"Thank you for your feedback. The process continues.\", gr.update(visible=False), gr.update(visible=False)\n",
        "        else:\n",
        "            return \"Please provide a reason:\", gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    # Use lambda functions to pass \"Yes\" or \"No\" as feedback values\n",
        "    feedback_button_yes.click(fn=lambda answer: handle_feedback(answer, \"Yes\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, feedback_textbox])\n",
        "    feedback_button_no.click(fn=lambda answer: handle_feedback(answer, \"No\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, feedback_textbox])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "aJgEhYQip_PK",
        "outputId": "98793f29-dde5-4156-b76b-5fdb19e5ac97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c76db17241769eda0c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c76db17241769eda0c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all working properly\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label=\"Enter your query\")\n",
        "        submit = gr.Button(\"Submit\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "    feedback_textbox = gr.Textbox(label=\"Feedback\", visible=False)\n",
        "    reason_textbox = gr.Textbox(label=\"Reason\", visible=False, interactive=True)\n",
        "    submit_reason_button = gr.Button(\"Submit Reason\", visible=False)  # Add a \"Submit Reason\" button\n",
        "\n",
        "    with gr.Row():\n",
        "        feedback_button_yes = gr.Button(\"Yes\")\n",
        "        feedback_button_no = gr.Button(\"No\")\n",
        "\n",
        "    def submit_event(user_query):\n",
        "        # Reset the visibility of feedback fields when a new query is submitted\n",
        "        return run_feedback_loop_simulation(user_query), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer, feedback_textbox, reason_textbox, submit_reason_button])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val):\n",
        "        # Display a thank you message if feedback is \"Yes\" or prompt for a reason if \"No\"\n",
        "        if feedback_val == \"Yes\":\n",
        "            return \"Thank you for your feedback. The process continues.\", gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "        else:\n",
        "            return \"Please provide a reason:\", gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    # Use lambda functions to pass \"Yes\" or \"No\" as feedback values\n",
        "    feedback_button_yes.click(fn=lambda answer: handle_feedback(answer, \"Yes\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, submit_reason_button])\n",
        "    feedback_button_no.click(fn=lambda answer: handle_feedback(answer, \"No\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, submit_reason_button])\n",
        "\n",
        "    def submit_reason(reason):\n",
        "        # Process the submitted reason (e.g., log it, save it)\n",
        "        print(f\"User reason: {reason}\")\n",
        "        return \"Thank you for your reason.\", gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    # Handle the reason submission\n",
        "    submit_reason_button.click(fn=submit_reason, inputs=reason_textbox, outputs=[feedback_textbox, reason_textbox, submit_reason_button])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "SWyHVJ3pqasB",
        "outputId": "e2bf81b2-d611-401c-9c80-4e28ad7fc535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://03f90251ec040f3f63.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://03f90251ec040f3f63.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def run_feedback_loop_simulation(user_query):\n",
        "    \"\"\"Simulates a feedback loop for a QA system.\"\"\"\n",
        "    query_type = classify_query(user_query)\n",
        "    print(f\"Query type classified as: {query_type}\")\n",
        "\n",
        "    enhanced_query = enhance_query(user_query)\n",
        "    print(f\"Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "    result = qa_chain({\"query\": enhanced_query})\n",
        "    answer = result['result']\n",
        "    print(f\"Answer:\\n{answer}\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "with gr.Blocks(title=\"✨Intelligent QA System with Feedback Loop🚀\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🤖 Intelligent QA System 🤖\n",
        "\n",
        "    Ask your questions, and let us know if the answer was helpful!  😊\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label=\"🤔 Enter your query\", placeholder=\"Type your question here...\")\n",
        "        submit = gr.Button(\"🚀 Submit Query\")\n",
        "\n",
        "    answer = gr.Textbox(label=\"✅ Answer\", interactive=False)\n",
        "    feedback_textbox = gr.Textbox(label=\"💬 Feedback\", visible=False)\n",
        "    reason_textbox = gr.Textbox(label=\"📝 Reason\", visible=False, interactive=True)\n",
        "    submit_reason_button = gr.Button(\"✅ Submit Reason\", visible=False)  # Add a \"Submit Reason\" button\n",
        "\n",
        "    with gr.Row():\n",
        "        feedback_button_yes = gr.Button(\"👍 Yes (Helpful)\")\n",
        "        feedback_button_no = gr.Button(\"👎 No (Not Helpful)\")\n",
        "\n",
        "    def submit_event(user_query):\n",
        "        return run_feedback_loop_simulation(user_query), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit.click(fn=submit_event, inputs=user_query, outputs=[answer, feedback_textbox, reason_textbox, submit_reason_button])\n",
        "\n",
        "    def handle_feedback(answer, feedback_val):\n",
        "        if feedback_val == \"👍 Yes (Helpful)\":\n",
        "            return \"Thank you for your feedback! 😊\", gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "        else:\n",
        "            return \"Could you please provide a reason? 🤔\", gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    feedback_button_yes.click(fn=lambda answer: handle_feedback(answer, \"👍 Yes (Helpful)\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, submit_reason_button])\n",
        "    feedback_button_no.click(fn=lambda answer: handle_feedback(answer, \"👎 No (Not Helpful)\"), inputs=answer, outputs=[feedback_textbox, reason_textbox, submit_reason_button])\n",
        "\n",
        "    def submit_reason(reason):\n",
        "        print(f\"User reason: {reason}\")\n",
        "        return \"Thank you for your feedback! We appreciate your input. 🙏\", gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    submit_reason_button.click(fn=submit_reason, inputs=reason_textbox, outputs=[feedback_textbox, reason_textbox, submit_reason_button])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "HBfSvc0qs2Ch",
        "outputId": "324f2182-d2fd-4825-d388-f24cafae6fb1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6cd9ecf24da35747fe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6cd9ecf24da35747fe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJgxRmI5Z5op"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}