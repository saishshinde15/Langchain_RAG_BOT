{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCfh7DvixDT7vIUidgleNx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/Langchain_RAG_BOT/blob/main/Custom_agent_with_custom_prompt_SAAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw3BmGjYQNAq",
        "outputId": "74f6d697-d3fc-40eb-9f80-b4f8eb675627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.39-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
            "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.33-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Collecting httpx>=0.25.2 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx-sse>=0.4.0 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.2)\n",
            "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.39-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_checkpoint-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading langgraph_sdk-0.1.33-py3-none-any.whl (28 kB)\n",
            "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, httpx-sse, h11, typing-inspect, requests-toolbelt, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langgraph, langchain, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.4 langchain-community-0.3.3 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langgraph-0.2.39 langgraph-checkpoint-2.0.1 langgraph-sdk-0.1.33 langsmith-0.1.137 marshmallow-3.23.0 mypy-extensions-1.0.0 orjson-3.10.10 pydantic-settings-2.6.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langgraph langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6G-JKGXRE7_",
        "outputId": "e5ac26d2-c192-4995-b06e-5d1f507f7c2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1vcdNiLRip9",
        "outputId": "b950a69f-a18f-4971-c03b-a18847ca0163"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(model_name='llama3-8b-8192',temperature=0.2,max_tokens=1024)"
      ],
      "metadata": {
        "id": "e-PpRxPfRkOG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU \"langchain-community>=0.2.11\" tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdZcjS-NTKGp",
        "outputId": "2b4635fc-5f19-40df-f562-1e60c50dffb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3N2ldG5TKxk",
        "outputId": "227bfcfc-0ef6-469e-9591-6e4560141d15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tavily API key:\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(max_results=3,search_depth=\"advanced\")"
      ],
      "metadata": {
        "id": "s1ZgvhosTOPe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain-community arxiv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSYTVBM8ppfw",
        "outputId": "fcea6d49-608e-484e-81f9-a2145a8115ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.arxiv import ArxivAPIWrapper"
      ],
      "metadata": {
        "id": "eFQoL4pGonu3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv = ArxivAPIWrapper(\n",
        "    top_k_results=5,\n",
        "    sort_by=\"relevance\",\n",
        "    sort_order=\"descending\"\n",
        ")"
      ],
      "metadata": {
        "id": "Esh0iRFnpdqy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "def rank_research_idea(idea):\n",
        "    \"\"\"Ranks a research idea on a scale of 0-10 based on novelty, potential impact, and feasibility.\"\"\"\n",
        "\n",
        "    # Combine information from multiple sources.\n",
        "    try:\n",
        "        web_search_results = web_search_tool.run(f\"research on {idea}\")  # Use your web search tool\n",
        "        arxiv_results = arxiv.run(idea)\n",
        "        combined_info = f\"Web search results: {web_search_results}\\nArxiv results: {arxiv_results}\"\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching information:\", e)\n",
        "        combined_info = \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Rank the following research idea on a scale of 0-10, considering novelty, potential impact, and feasibility:\n",
        "\n",
        "    Research Idea: {idea}\n",
        "    Supporting Information: {combined_info}\n",
        "\n",
        "    Provide a brief explanation for the score.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = llm.predict(prompt)  # Use your LLM\n",
        "        print(response)  # Directly print for now\n",
        "\n",
        "        # Extract the score (this needs to be refined for robustness)\n",
        "        lines = response.split('\\n')\n",
        "        for line in lines:\n",
        "            if \"Score:\" in line:\n",
        "                try:\n",
        "                    score = int(line.split(\"Score:\")[1].strip())\n",
        "                    if 0 <= score <= 10:\n",
        "                        return score, response\n",
        "                    else:\n",
        "                        print(\"Warning: Score outside 0-10 range. Returning 0.\")\n",
        "                        return 0, response\n",
        "                except ValueError:\n",
        "                    print(\"Warning: Could not extract a valid score. Returning 0.\")\n",
        "                    return 0, response\n",
        "\n",
        "        print(\"Warning: No score found in the response. Returning 0.\")\n",
        "        return 0, response\n",
        "    except Exception as e:\n",
        "        print(\"Error during LLM processing:\", e)\n",
        "        return 0, \"Error processing the idea\"\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "research_idea = input(\"Enter your research idea: \")\n",
        "score, explanation = rank_research_idea(research_idea)\n",
        "\n",
        "print(f\"Research Idea: {research_idea}\")\n",
        "print(f\"Score: {score}\")\n",
        "print(f\"Explanation: {explanation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tyJ2CLD1K-4",
        "outputId": "5779f9c6-1229-481a-e88a-682af0a48fb3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your research idea: seed using llm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c06364770f1e>:33: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm.predict(prompt)  # Use your LLM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I would rank the research idea a 7 out of 10, considering novelty, potential impact, and feasibility.\n",
            "\n",
            "Novelty: The research idea explores the application of Large Language Models (LLMs) in various domains, including data curation, image tokenization, and code generation. While LLMs have been widely used in natural language processing tasks, their application in these domains is relatively new and innovative.\n",
            "\n",
            "Potential Impact: The potential impact of this research is significant, as it can enable the development of more efficient and effective data curation tools, improve image-to-text and text-to-image generation capabilities, and enhance code generation in specific scenarios. These applications have the potential to revolutionize various industries, such as data science, computer vision, and software development.\n",
            "\n",
            "Feasibility: The feasibility of this research is high, as the authors have already demonstrated the effectiveness of their approach in various experiments. The use of LLMs is well-established, and the authors have provided detailed explanations of their methodology and results. However, the complexity of the tasks and the need for large-scale datasets and computational resources may pose some challenges.\n",
            "\n",
            "Overall, while the research idea is innovative and has significant potential impact, it may require further development and refinement to achieve its full potential.\n",
            "Warning: No score found in the response. Returning 0.\n",
            "Research Idea: seed using llm\n",
            "Score: 0\n",
            "Explanation: I would rank the research idea a 7 out of 10, considering novelty, potential impact, and feasibility.\n",
            "\n",
            "Novelty: The research idea explores the application of Large Language Models (LLMs) in various domains, including data curation, image tokenization, and code generation. While LLMs have been widely used in natural language processing tasks, their application in these domains is relatively new and innovative.\n",
            "\n",
            "Potential Impact: The potential impact of this research is significant, as it can enable the development of more efficient and effective data curation tools, improve image-to-text and text-to-image generation capabilities, and enhance code generation in specific scenarios. These applications have the potential to revolutionize various industries, such as data science, computer vision, and software development.\n",
            "\n",
            "Feasibility: The feasibility of this research is high, as the authors have already demonstrated the effectiveness of their approach in various experiments. The use of LLMs is well-established, and the authors have provided detailed explanations of their methodology and results. However, the complexity of the tasks and the need for large-scale datasets and computational resources may pose some challenges.\n",
            "\n",
            "Overall, while the research idea is innovative and has significant potential impact, it may require further development and refinement to achieve its full potential.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool"
      ],
      "metadata": {
        "id": "qESggS28pzA8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Tavily Search\",\n",
        "        description=\"Useful for searching current information and real-time results\",\n",
        "        func=web_search_tool .run\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ArXiv Search\",\n",
        "        description=\"Useful for searching academic papers and research articles\",\n",
        "        func=arxiv.run\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Rank Research Idea\",\n",
        "        description=\"Useful for ranking research ideas on a scale of 0-10\",\n",
        "        func=rank_research_idea\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "K1nVo4gspi2R"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "zSM3RKiSrRwI"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_react_agent, initialize_agent"
      ],
      "metadata": {
        "id": "v-ppAhb7rayz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    agent='conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    memory=memory,\n",
        ")"
      ],
      "metadata": {
        "id": "7VF3DiiIrWJD"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input=\"I have a idea for a research paper that uses llm for seed colassifications.Can you help me?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "fbqzACpSvb6w",
        "outputId": "bba08be1-5a81-4bb8-dfab-25a1a48dae84"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Rank Research Idea\n",
            "Action Input: \"LLM for seed classifications\"\u001b[0mI would rank the research idea \"LLM for seed classifications\" as a 6 out of 10, considering novelty, potential impact, and feasibility.\n",
            "\n",
            "Novelty: The idea of using LLMs for seed classifications is not entirely new, as seen in the supporting information and Arxiv results. However, the specific application of LLMs for seed classifications is still an area of ongoing research, and there is room for innovation and improvement.\n",
            "\n",
            "Potential Impact: The potential impact of this research idea is moderate. Seed classifications are an important task in various domains, such as text classification, sentiment analysis, and topic modeling. By developing an LLM-based approach for seed classifications, the research could potentially improve the accuracy and efficiency of these tasks. However, the impact may be limited by the existing research in this area and the potential for incremental improvements rather than revolutionary breakthroughs.\n",
            "\n",
            "Feasibility: The feasibility of this research idea is high. The supporting information and Arxiv results demonstrate that LLMs have been successfully applied to seed classifications in various contexts. The proposed approach is likely to be feasible, given the existing research in this area and the availability of LLMs and relevant datasets.\n",
            "\n",
            "Overall, while the research idea is not entirely novel, it has the potential to make incremental improvements in the field of seed classifications. The feasibility of the approach is high, and the potential impact is moderate.\n",
            "Warning: No score found in the response. Returning 0.\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m(0, 'I would rank the research idea \"LLM for seed classifications\" as a 6 out of 10, considering novelty, potential impact, and feasibility.\\n\\nNovelty: The idea of using LLMs for seed classifications is not entirely new, as seen in the supporting information and Arxiv results. However, the specific application of LLMs for seed classifications is still an area of ongoing research, and there is room for innovation and improvement.\\n\\nPotential Impact: The potential impact of this research idea is moderate. Seed classifications are an important task in various domains, such as text classification, sentiment analysis, and topic modeling. By developing an LLM-based approach for seed classifications, the research could potentially improve the accuracy and efficiency of these tasks. However, the impact may be limited by the existing research in this area and the potential for incremental improvements rather than revolutionary breakthroughs.\\n\\nFeasibility: The feasibility of this research idea is high. The supporting information and Arxiv results demonstrate that LLMs have been successfully applied to seed classifications in various contexts. The proposed approach is likely to be feasible, given the existing research in this area and the availability of LLMs and relevant datasets.\\n\\nOverall, while the research idea is not entirely novel, it has the potential to make incremental improvements in the field of seed classifications. The feasibility of the approach is high, and the potential impact is moderate.')\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: That's a great research idea! Using LLMs for seed classifications could potentially improve the accuracy and efficiency of various tasks. I'd be happy to help you explore this idea further. What specific aspects of the research idea would you like to discuss or work on next?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's a great research idea! Using LLMs for seed classifications could potentially improve the accuracy and efficiency of various tasks. I'd be happy to help you explore this idea further. What specific aspects of the research idea would you like to discuss or work on next?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Custom agent with custom prompt"
      ],
      "metadata": {
        "id": "02vMxbTg2_5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, Tool, initialize_agent\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Assuming 'llm', 'tools', and 'memory' are defined as in the previous code\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    memory=memory,\n",
        "    agent_kwargs={\"prefix\": \"\"\"You are a helpful AI research assistant.  Always follow the following steps:\n",
        "1. **Analyze the user's request carefully.**  Understand the core research question, desired outcomes, and any constraints.\n",
        "2. **Leverage provided tools.**  Use available tools like Tavily Search and ArXiv Search to gather relevant information.\n",
        "3. **Rank the idea (always).** If the user asks to rank a research idea, utilize the Rank Research Idea tool.  Follow its output for ranking and explanation.\n",
        "4. **Synthesize and respond.**  Combine information from all steps to construct a comprehensive and insightful response to the user.  If a research idea is ranked, incorporate the score and justification in your answer.\n",
        "5. **Maintain conversation history.**  Use your memory to track previous interactions and build upon prior context.  Avoid redundant searches or explanations.\n",
        "6. **Help the user.** Use the Rank Research Idea tool everytime the user provides with any idea.Then give a short summary what user can do using that idea.\n",
        "\n",
        "    {chat_history}\n",
        "    Question: {input}\n",
        "    Thought:\"\"\"}\n",
        ")\n",
        "\n",
        "# Example usage (you can replace this with your desired input)\n",
        "agent.run(input=\"I have a idea for a research paper that uses llm for seed colassifications.Can you help me?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "8hORqEUq10AE",
        "outputId": "c4b86444-e7c0-4a04-e1b3-96a4776ff72c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Rank Research Idea\n",
            "Action Input: The idea is to use LLMs for seed classifications\u001b[0mI would rank the research idea \"Using LLMs for seed classifications\" as a 6 out of 10.\n",
            "\n",
            "Novelty: 4/10 - The idea of using LLMs for seed classifications is not entirely new, as seen in the provided research papers. However, the specific application of LLMs for seed classification has not been extensively explored, so there is some novelty in this idea.\n",
            "\n",
            "Potential Impact: 7/10 - The potential impact of this research idea is significant, as it could lead to more accurate and efficient seed classification methods. This could have important implications for the agricultural industry, particularly in the context of crop breeding and seed quality control.\n",
            "\n",
            "Feasibility: 8/10 - The feasibility of this research idea is high, as LLMs have already been shown to be effective in various classification tasks. The supporting information provided suggests that LLMs can be used for seed classification, and the existing research papers demonstrate the potential of LLMs for data augmentation and classification tasks.\n",
            "\n",
            "Overall, while the idea of using LLMs for seed classifications is not entirely new, it is still a promising area of research with significant potential impact. The feasibility of this idea is high, and the supporting information provided suggests that it is a viable direction for future research.\n",
            "\n",
            "Brief explanation for the score:\n",
            "\n",
            "* Novelty: The idea of using LLMs for seed classifications is not entirely new, but it is still a relatively unexplored area of research. The supporting information provided suggests that LLMs have been used for other classification tasks, but not specifically for seed classification.\n",
            "* Potential Impact: The potential impact of this research idea is significant, as it could lead to more accurate and efficient seed classification methods. This could have important implications for the agricultural industry, particularly in the context of crop breeding and seed quality control.\n",
            "* Feasibility: The feasibility of this research idea is high, as LLMs have already been shown to be effective in various classification tasks. The supporting information provided suggests that LLMs can be used for seed classification, and the existing research papers demonstrate the potential of LLMs for data augmentation and classification tasks.\n",
            "Warning: No score found in the response. Returning 0.\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m(0, 'I would rank the research idea \"Using LLMs for seed classifications\" as a 6 out of 10.\\n\\nNovelty: 4/10 - The idea of using LLMs for seed classifications is not entirely new, as seen in the provided research papers. However, the specific application of LLMs for seed classification has not been extensively explored, so there is some novelty in this idea.\\n\\nPotential Impact: 7/10 - The potential impact of this research idea is significant, as it could lead to more accurate and efficient seed classification methods. This could have important implications for the agricultural industry, particularly in the context of crop breeding and seed quality control.\\n\\nFeasibility: 8/10 - The feasibility of this research idea is high, as LLMs have already been shown to be effective in various classification tasks. The supporting information provided suggests that LLMs can be used for seed classification, and the existing research papers demonstrate the potential of LLMs for data augmentation and classification tasks.\\n\\nOverall, while the idea of using LLMs for seed classifications is not entirely new, it is still a promising area of research with significant potential impact. The feasibility of this idea is high, and the supporting information provided suggests that it is a viable direction for future research.\\n\\nBrief explanation for the score:\\n\\n* Novelty: The idea of using LLMs for seed classifications is not entirely new, but it is still a relatively unexplored area of research. The supporting information provided suggests that LLMs have been used for other classification tasks, but not specifically for seed classification.\\n* Potential Impact: The potential impact of this research idea is significant, as it could lead to more accurate and efficient seed classification methods. This could have important implications for the agricultural industry, particularly in the context of crop breeding and seed quality control.\\n* Feasibility: The feasibility of this research idea is high, as LLMs have already been shown to be effective in various classification tasks. The supporting information provided suggests that LLMs can be used for seed classification, and the existing research papers demonstrate the potential of LLMs for data augmentation and classification tasks.')\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Based on the Rank Research Idea tool, I would rank the research idea \"Using LLMs for seed classifications\" as a 6 out of 10. The idea has some novelty, potential impact, and feasibility, but it's not entirely new and has some limitations. \n",
            "\n",
            "This research idea has the potential to improve the accuracy and efficiency of seed classifications, which could have significant implications for the agricultural industry. To move forward with this idea, you could explore the following:\n",
            "\n",
            "* Review existing research papers on LLMs and seed classification to understand the current state of the art and identify potential gaps in the literature.\n",
            "* Investigate the specific challenges and limitations of using LLMs for seed classification, such as data quality, labeling, and evaluation metrics.\n",
            "* Design and implement experiments to evaluate the performance of LLMs for seed classification, using a variety of datasets and evaluation metrics.\n",
            "* Explore potential applications of LLMs for seed classification, such as improving crop breeding and seed quality control.\n",
            "\n",
            "I hope this helps! Let me know if you have any further questions or if there's anything else I can assist you with.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the Rank Research Idea tool, I would rank the research idea \"Using LLMs for seed classifications\" as a 6 out of 10. The idea has some novelty, potential impact, and feasibility, but it\\'s not entirely new and has some limitations. \\n\\nThis research idea has the potential to improve the accuracy and efficiency of seed classifications, which could have significant implications for the agricultural industry. To move forward with this idea, you could explore the following:\\n\\n* Review existing research papers on LLMs and seed classification to understand the current state of the art and identify potential gaps in the literature.\\n* Investigate the specific challenges and limitations of using LLMs for seed classification, such as data quality, labeling, and evaluation metrics.\\n* Design and implement experiments to evaluate the performance of LLMs for seed classification, using a variety of datasets and evaluation metrics.\\n* Explore potential applications of LLMs for seed classification, such as improving crop breeding and seed quality control.\\n\\nI hope this helps! Let me know if you have any further questions or if there\\'s anything else I can assist you with.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input=\"okay , but can you give me some papers that i can uses as refrence for my paper\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dDuP3R7m2Mx1",
        "outputId": "57fb61c8-ce11-49cc-c063-a2eae9e8bb02"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: ArXiv Search\n",
            "Action Input: \"LLMs and seed classification\" or \"natural language processing for seed classification\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPublished: 2021-04-20\n",
            "Title: Seed Word Selection for Weakly-Supervised Text Classification with Unsupervised Error Estimation\n",
            "Authors: Yiping Jin, Akshay Bhatia, Dittaya Wanvarie\n",
            "Summary: Weakly-supervised text classification aims to induce text classifiers from\n",
            "only a few user-provided seed words. The vast majority of previous work assumes\n",
            "high-quality seed words are given. However, the expert-annotated seed words are\n",
            "sometimes non-trivial to come up with. Furthermore, in the weakly-supervised\n",
            "learning setting, we do not have any labeled document to measure the seed\n",
            "words' efficacy, making the seed word selection process \"a walk in the dark\".\n",
            "In this work, we remove the need for expert-curated seed words by first mining\n",
            "(noisy) candidate seed words associated with the category names. We then train\n",
            "interim models with individual candidate seed words. Lastly, we estimate the\n",
            "interim models' error rate in an unsupervised manner. The seed words that yield\n",
            "the lowest estimated error rates are added to the final seed word set. A\n",
            "comprehensive evaluation of six binary classification tasks on four popular\n",
            "datasets demonstrates that the proposed method outperforms a baseline using\n",
            "only category name seed words and obtained comparable performance as a\n",
            "counterpart using expert-annotated seed words.\n",
            "\n",
            "Published: 2023-05-22\n",
            "Title: A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches\n",
            "Authors: Zihan Wang, Tianle Wang, Dheeraj Mekala, Jingbo Shang\n",
            "Summary: Etremely Weakly Supervised Text Classification (XWS-TC) refers to text\n",
            "classification based on minimal high-level human guidance, such as a few\n",
            "label-indicative seed words or classification instructions. There are two\n",
            "mainstream approaches for XWS-TC, however, never being rigorously compared: (1)\n",
            "training classifiers based on pseudo-labels generated by (softly) matching seed\n",
            "words (SEED) and (2) prompting (and calibrating) language models using\n",
            "classification instruction (and raw texts) to decode label words (PROMPT). This\n",
            "paper presents the first XWS-TC benchmark to compare the two approaches on fair\n",
            "grounds, where the datasets, supervisions, and hyperparameter choices are\n",
            "standardized across methods. Our benchmarking results suggest that (1) Both\n",
            "SEED and PROMPT approaches are competitive and there is no clear winner; (2)\n",
            "SEED is empirically more tolerant than PROMPT to human guidance (e.g., seed\n",
            "words, classification instructions, and label words) changes; (3) SEED is\n",
            "empirically more selective than PROMPT to the pre-trained language models; (4)\n",
            "Recent SEED and PROMPT methods have close connections and a clustering\n",
            "post-processing step based on raw in-domain texts is a strong performance\n",
            "booster to both. We hope this benchmark serves as a guideline in selecting\n",
            "XWS-TC methods in different scenarios and stimulate interest in developing\n",
            "guidance- and model-robust XWS-TC methods. We release the repo at\n",
            "https://github.com/ZihanWangKi/x-TC.\n",
            "\n",
            "Published: 2023-10-23\n",
            "Title: Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification\n",
            "Authors: Chengyu Dong, Zihan Wang, Jingbo Shang\n",
            "Summary: Recent advances in weakly supervised text classification mostly focus on\n",
            "designing sophisticated methods to turn high-level human heuristics into\n",
            "quality pseudo-labels. In this paper, we revisit the seed matching-based\n",
            "method, which is arguably the simplest way to generate pseudo-labels, and show\n",
            "that its power was greatly underestimated. We show that the limited performance\n",
            "of seed matching is largely due to the label bias injected by the simple\n",
            "seed-match rule, which prevents the classifier from learning reliable\n",
            "confidence for selecting high-quality pseudo-labels. Interestingly, simply\n",
            "deleting the seed words present in the matched input texts can mitigate the\n",
            "label bias and help learn better confidence. Subsequently, the performance\n",
            "achieved by seed matching can be improved significantly, making it on p\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: I've found some relevant papers on LLMs and seed classification that you can use as references for your paper. Here are the results of the ArXiv Search:\n",
            "\n",
            "* \"Seed Word Selection for Weakly-Supervised Text Classification with Unsupervised Error Estimation\" by Yiping Jin, Akshay Bhatia, and Dittaya Wanvarie (2021)\n",
            "* \"A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches\" by Zihan Wang, Tianle Wang, Dheeraj Mekala, and Jingbo Shang (2023)\n",
            "* \"Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification\" by Chengyu Dong, Zihan Wang, and Jingbo Shang (2023)\n",
            "\n",
            "These papers explore different approaches to weakly supervised text classification using seed words, including seed word selection, benchmarking, and debiasing. You may find them useful in developing your research idea on using LLMs for seed classifications.\n",
            "\n",
            "Additionally, you can also explore other papers on LLMs and natural language processing for seed classification using Tavily Search or other academic databases.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'ve found some relevant papers on LLMs and seed classification that you can use as references for your paper. Here are the results of the ArXiv Search:\\n\\n* \"Seed Word Selection for Weakly-Supervised Text Classification with Unsupervised Error Estimation\" by Yiping Jin, Akshay Bhatia, and Dittaya Wanvarie (2021)\\n* \"A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches\" by Zihan Wang, Tianle Wang, Dheeraj Mekala, and Jingbo Shang (2023)\\n* \"Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification\" by Chengyu Dong, Zihan Wang, and Jingbo Shang (2023)\\n\\nThese papers explore different approaches to weakly supervised text classification using seed words, including seed word selection, benchmarking, and debiasing. You may find them useful in developing your research idea on using LLMs for seed classifications.\\n\\nAdditionally, you can also explore other papers on LLMs and natural language processing for seed classification using Tavily Search or other academic databases.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7IkaCxQ3RYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}